{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7eiDWcM_MC3H"
   },
   "source": [
    "# <font color='red'>Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfe2NTQtLq11"
   },
   "source": [
    "**There will be some functions that start with the word \"grader\" ex: grader_weights(), grader_sigmoid(), grader_logloss() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fk5DSPCLxqT-"
   },
   "source": [
    "<font color='red'> Importing packages</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "42Et8BKIxnsp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpSk3WQBx7TQ"
   },
   "source": [
    "<font color='red'>Creating custom dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BsMp0oWzx6dv"
   },
   "outputs": [],
   "source": [
    "# please don't change random_state\n",
    "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
    "# make_classification is used to create custom dataset \n",
    "# Please check this link (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "L8W2fg1cyGdX",
    "outputId": "029d4c84-03b2-4143-a04c-34ff49c88890"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 15), (50000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x99RWCgpqNHw"
   },
   "source": [
    "<font color='red'>Splitting data into train and test </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0Kh4dBfVyJMP"
   },
   "outputs": [],
   "source": [
    "#please don't change random state\n",
    "# you need not standardize the data as it is already standardized\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "0DR_YMBsyOci",
    "outputId": "732014d9-1731-4d3f-918f-a9f5255ee149"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37500, 15), (37500,), (12500, 15), (12500,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
    "# type(X_train)\n",
    "# len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BW4OHswfqjHR"
   },
   "source": [
    "# <font color='red' size=5>SGD classifier</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "id": "3HpvTwDHyQQy",
    "outputId": "5729f08c-079a-4b17-bf51-f9aeb5abb13b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(eta0=0.0001, learning_rate=&#x27;constant&#x27;, loss=&#x27;log_loss&#x27;,\n",
       "              random_state=15, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(eta0=0.0001, learning_rate=&#x27;constant&#x27;, loss=&#x27;log_loss&#x27;,\n",
       "              random_state=15, verbose=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier(eta0=0.0001, learning_rate='constant', loss='log_loss',\n",
       "              random_state=15, verbose=2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha : float\n",
    "# Constant that multiplies the regularization term. \n",
    "\n",
    "# eta0 : double\n",
    "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
    "\n",
    "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log_loss', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
    "clf\n",
    "# Please check this documentation (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "id": "YYaVyQ2lyXcr",
    "outputId": "dc0bf840-b37e-4552-e513-84b64f6c64c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.77, NNZs: 15, Bias: -0.316653, T: 37500, Avg. loss: 0.455552\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.91, NNZs: 15, Bias: -0.472747, T: 75000, Avg. loss: 0.394686\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.98, NNZs: 15, Bias: -0.580082, T: 112500, Avg. loss: 0.385711\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.02, NNZs: 15, Bias: -0.658292, T: 150000, Avg. loss: 0.382083\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.04, NNZs: 15, Bias: -0.719528, T: 187500, Avg. loss: 0.380486\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.05, NNZs: 15, Bias: -0.763409, T: 225000, Avg. loss: 0.379578\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.795106, T: 262500, Avg. loss: 0.379150\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.819925, T: 300000, Avg. loss: 0.378856\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.07, NNZs: 15, Bias: -0.837805, T: 337500, Avg. loss: 0.378585\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.08, NNZs: 15, Bias: -0.853138, T: 375000, Avg. loss: 0.378630\n",
      "Total training time: 0.14 seconds.\n",
      "Convergence after 10 epochs took 0.14 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(eta0=0.0001, learning_rate=&#x27;constant&#x27;, loss=&#x27;log_loss&#x27;,\n",
       "              random_state=15, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(eta0=0.0001, learning_rate=&#x27;constant&#x27;, loss=&#x27;log_loss&#x27;,\n",
       "              random_state=15, verbose=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier(eta0=0.0001, learning_rate='constant', loss='log_loss',\n",
       "              random_state=15, verbose=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X=X_train, y=y_train) # fitting our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "id": "EAfkVI6GyaRO",
    "outputId": "bc88f920-6531-4106-9b4c-4dabb6d72b47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.42336692,  0.18547565, -0.14859036,  0.34144407, -0.2081867 ,\n",
       "          0.56016579, -0.45242483, -0.09408813,  0.2092732 ,  0.18084126,\n",
       "          0.19705191,  0.00421916, -0.0796037 ,  0.33852802,  0.02266721]]),\n",
       " (1, 15),\n",
       " array([-0.8531383]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_, clf.coef_.shape, clf.intercept_\n",
    "#clf.coef_ will return the weights\n",
    "#clf.coef_.shape will return the shape of weights\n",
    "#clf.intercept_ will return the intercept term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9344"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(clf.predict(X_test)).count(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-CcGTKgsMrY"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "## <font color='red' size=5> Implement Logistic Regression with L2 regularization Using SGD: without using sklearn </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1_8bdzitDlM"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "1.  We will be giving you some functions, please write code in that functions only.\n",
    "\n",
    "2.  After every function, we will be giving you expected output, please make sure that you get that output. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zU2Y3-FQuJ3z"
   },
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "* Initialize the weight_vector and intercept term to zeros (Write your code in <font color='blue'>def initialize_weights()</font>)\n",
    "\n",
    "* Create a loss function (Write your code in <font color='blue'>def logloss()</font>) \n",
    "\n",
    " $log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$\n",
    "- for each epoch:\n",
    "\n",
    "    - for each batch of data points in train: (keep batch size=1)\n",
    "\n",
    "        - calculate the gradient of loss function w.r.t each weight in weight vector (write your code in <font color='blue'>def gradient_dw()</font>)\n",
    "\n",
    "        $dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)})$ <br>\n",
    "\n",
    "        - Calculate the gradient of the intercept (write your code in <font color='blue'> def gradient_db()</font>) <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
    "\n",
    "           $ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$\n",
    "\n",
    "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
    "        $w^{(t+1)}← w^{(t)}+α(dw^{(t)}) $<br>\n",
    "\n",
    "        $b^{(t+1)}←b^{(t)}+α(db^{(t)}) $\n",
    "    - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
    "    - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
    "        you can stop the training\n",
    "    - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZR_HgjgS_wKu"
   },
   "source": [
    "<font color='blue'>Initialize weights </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "GecwYV9fsKZ9"
   },
   "outputs": [],
   "source": [
    "def initialize_weights(row_vector):\n",
    "    ''' In this function, we will initialize our weights and bias'''\n",
    "    #initialize the weights as 1d array consisting of all zeros similar to the dimensions of row_vector\n",
    "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
    "    #initialize bias to zero\n",
    "    w=np.zeros_like(row_vector)\n",
    "    b=0\n",
    "#     print (X_train)\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MI5SAjP9ofN"
   },
   "source": [
    "<font color='red'>Grader function - 1 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Pv1llH429wG5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X_train[0] \n",
    "w,b = initialize_weights(dim)\n",
    "def grader_weights(w,b):\n",
    "  assert((len(w)==len(dim)) and b==0 and np.sum(w)==0.0)\n",
    "  return True\n",
    "grader_weights(w,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QN83oMWy_5rv"
   },
   "source": [
    "<font color='blue'>Compute sigmoid </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPv4NJuxABgs"
   },
   "source": [
    "$sigmoid(z)= 1/(1+exp(-z))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nAfmQF47_Sd6"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    ''' In this function, we will return sigmoid of z'''\n",
    "    # compute sigmoid(z) and return\n",
    "    sigm=1/(1+np.exp(-z))\n",
    "    return sigm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YrGDwg3Ae4m"
   },
   "source": [
    "<font color='red'>Grader function - 2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "P_JASp_NAfK_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_sigmoid(z):\n",
    "  val=sigmoid(z)\n",
    "  assert(val==0.8807970779778823)\n",
    "  return True\n",
    "grader_sigmoid(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gS7JXbcrBOFF"
   },
   "source": [
    "<font color='blue'> Compute loss </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfEiS22zBVYy"
   },
   "source": [
    "$log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "VaFDgsp3sKi6"
   },
   "outputs": [],
   "source": [
    "def logloss(y_true,y_pred):\n",
    "    # you have been given two arrays y_true and y_pred and you have to calculate the logloss\n",
    "    #while dealing with numpy arrays you can use vectorized operations for quicker calculations as compared to using loops\n",
    "    #https://www.pythonlikeyoumeanit.com/Module3_IntroducingNumpy/VectorizedOperations.html\n",
    "    #https://www.geeksforgeeks.org/vectorized-operations-in-numpy/\n",
    "    #write your code here\n",
    "    sum=0\n",
    "    for i in range(len(y_true)):\n",
    "        loss=((y_true[i]*np.log10(y_pred[i]))+((1-y_true[i])*np.log10(1-y_pred[i])))\n",
    "        sum+=loss\n",
    "    log_loss=(-1/len(y_true))*sum\n",
    "    \n",
    "    return log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zs1BTXVSClBt"
   },
   "source": [
    "<font color='red'>Grader function - 3 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "LzttjvBFCuQ5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#round off the value to 8 values\n",
    "def grader_logloss(true,pred):\n",
    "  loss=logloss(true,pred)\n",
    "  assert(np.round(loss,6)==0.076449)\n",
    "  return True\n",
    "true=np.array([1,1,0,1,0])\n",
    "pred=np.array([0.9,0.8,0.1,0.8,0.2])\n",
    "grader_logloss(true,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQabIadLCBAB"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to  'w' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTMxiYKaCQgd"
   },
   "source": [
    "$dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)}$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "NMVikyuFsKo5"
   },
   "outputs": [],
   "source": [
    "\n",
    "#make sure that the sigmoid function returns a scalar value, you can use dot function operation\n",
    "def gradient_dw(x,y,w,b,alpha,N):\n",
    "    '''In this function, we will compute the gardient w.r.to w '''\n",
    "    dw=x*(y-sigmoid(np.dot(w,x)+b))-((alpha*w)/N)  #dot product of w and x  \n",
    "    #https://www.tutorialspoint.com/numpy/numpy_dot.htm#:~:text=dot(),-Advertisements&text=This%20function%20returns%20the%20dot,the%20equivalent%20to%20matrix%20multiplication.\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUFLNqL_GER9"
   },
   "source": [
    "<font color='red'>Grader function - 4 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "WI3xD8ctGEnJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_dw(x,y,w,b,alpha,N):\n",
    "  grad_dw=gradient_dw(x,y,w,b,alpha,N)\n",
    "  assert(np.round(np.sum(grad_dw),5)==4.75684)\n",
    "  return True\n",
    "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y=0\n",
    "grad_w=np.array([ 0.03364887,  0.03612727,  0.02786927,  0.08547455, -0.12870234,\n",
    "       -0.02555288,  0.11858013,  0.13305576,  0.07310204,  0.15149245,\n",
    "       -0.05708987, -0.064768  ,  0.18012332, -0.16880843, -0.27079877])\n",
    "grad_b=0.5\n",
    "alpha=0.0001\n",
    "N=len(X_train)\n",
    "grader_dw(grad_x,grad_y,grad_w,grad_b,alpha,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LE8g84_GI62n"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to 'b' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHvTYZzZJJ_N"
   },
   "source": [
    "$ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "0nUf2ft4EZp8"
   },
   "outputs": [],
   "source": [
    "#sb should be a scalar value\n",
    "def gradient_db(x,y,w,b):\n",
    "    \n",
    "     '''In this function, we will compute gradient w.r.to b '''\n",
    "     db=y-sigmoid(np.dot(w,x)+b)    \n",
    "     return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbcBzufVG6qk"
   },
   "source": [
    "<font color='red'>Grader function - 5 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "TfFDKmscG5qZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_db(x,y,w,b):\n",
    "  grad_db=gradient_db(x,y,w,b)\n",
    "  assert(np.round(grad_db,4)==-0.3714)\n",
    "  return True\n",
    "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y=0.5\n",
    "grad_b=0.1\n",
    "grad_w=np.array([ 0.03364887,  0.03612727,  0.02786927,  0.08547455, -0.12870234,\n",
    "       -0.02555288,  0.11858013,  0.13305576,  0.07310204,  0.15149245,\n",
    "       -0.05708987, -0.064768  ,  0.18012332, -0.16880843, -0.27079877])\n",
    "alpha=0.0001\n",
    "N=len(X_train)\n",
    "grader_db(grad_x,grad_y,grad_w,grad_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction function used to compute predicted_y given the dataset X\n",
    "def pred(w,b, X):\n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    for i in range(N):\n",
    "        z=np.dot(w,X[i])+b\n",
    "        predict.append(sigmoid(z))\n",
    "    return np.array(predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCK0jY_EOvyU"
   },
   "source": [
    "<font color='blue'> Implementing logistic regression</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train (X_train,y_train,X_test,y_test,epochs,alpha,eta0):\n",
    "    w,b = initialize_weights(X_train[0])\n",
    "    trainn_loss=[]\n",
    "    testt_loss=[]\n",
    "    for i in range(epochs):\n",
    "\n",
    "        for j in range(N):\n",
    "            dw=gradient_dw(X_train[j],y_train[j],w,b,alpha,N)\n",
    "            db=gradient_db(X_train[j],y_train[j],w,b)\n",
    "            w=(w+(eta0*dw))\n",
    "            b=(b+(eta0*db))\n",
    "            \n",
    "        predict_train=pred(w,b,X_train)\n",
    "        loss_train=logloss(y_train,predict_train)\n",
    "        trainn_loss.append(loss_train)\n",
    "        predict_test=pred(w,b,X_test)\n",
    "        loss_test=logloss(y_test,predict_test)\n",
    "        testt_loss.append(loss_test)\n",
    "        if i==0 :\n",
    "            continue                                              \n",
    "        else:                                                     \n",
    "            if abs(trainn_loss[i]-trainn_loss[i-1])>.001:\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "    return w,b, trainn_loss,testt_loss\n",
    "\n",
    "alpha=0.0001\n",
    "eta0=0.0001\n",
    "N=len(X_train)\n",
    "epochs=20\n",
    "w,b,train_loss,test_loss=train (X_train,y_train,X_test,y_test,epochs,alpha,eta0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "length=len(train_loss)\n",
    "epoch=[i for i in range(length)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.02335453, -0.00218638,  0.01456819, -0.00564088,  0.02929518,\n",
       "         -0.01458265,  0.00573493, -0.00314698, -0.00461857, -0.02598241,\n",
       "         -0.01435484,  0.00676448,  0.01347985, -0.00143244, -0.0025967 ]]),\n",
       " array([0.13471569]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
    "\n",
    "w-clf.coef_, b-clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4Zf_wPARlwY"
   },
   "source": [
    "## <font color='red'>Goal of assignment</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3eF_VSPSH2z"
   },
   "source": [
    "Compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in order of 10^-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Grader function - 6 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The custom weights are correct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this grader function should return True\n",
    "#the difference between custom weights and clf.coef_ should be less than or equal to 0.05\n",
    "def differece_check_grader(w,b,coef,intercept):\n",
    "    val_array=np.abs(np.array(w-coef))\n",
    "    assert(np.all(val_array<=0.05))\n",
    "    print('The custom weights are correct')\n",
    "    return True\n",
    "differece_check_grader(w,b,clf.coef_,clf.intercept_)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "230YbSgNSUrQ"
   },
   "source": [
    "<font color='blue'>Plot your train and test loss vs epochs </font>\n",
    "\n",
    "plot epoch number on X-axis and loss on Y-axis and make sure that the curve is converging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "1O6GrRt7UeCJ"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(epoch,train_loss, label='tain log loss')\n",
    "plt.plot(epoch,test_loss, label='test log loss')\n",
    "plt.scatter(epoch,train_loss)\n",
    "plt.scatter(epoch,test_loss)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('log loss')\n",
    "plt.title('log loss curve of logistic regression')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FUN8puFoEZtU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-k28U1xDsLIO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RMokBfs3-2PY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
